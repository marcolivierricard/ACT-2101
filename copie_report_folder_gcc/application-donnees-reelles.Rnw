%% Application à des données réelles
% le Sweaveopt
\SweaveOpts{prefix.string=images/fig}

\chapter{Application à des données réelles}
\label{chap:application} 

\section{Analyse de données}

Pour mettre en application l'approche proposée par \cite{chavez2016extreme}, deux jeux de données du paquetage \texttt{CASdatasets} sont utilisés. Soit \texttt{auscathist} et \texttt{nzcathist}. Ces données représentent respectivement l'historique des catastrophes naturelles pour l'Australie ainsi que pour la Nouvelle-Zélande. Les deux jeux de données contiennent également différentes statistiques de ces catastrophes. Voici une liste des variables disponibles:
\begin{itemize}
\item \texttt{Year}: l'année d'occurence de la catastrophe.
\item \texttt{Quarter}: le trimestre d'occurence de la catastrophne.
\item \texttt{Date}: la date d'occurence complète de la catastrophe.
\item \texttt{FirstDay}: la date de la première journée d'occurence de la catastrophe.
\item \texttt{LastDay}: la date de la dernière journée de la catastrophe (seulement disponible pour l'Australie).
\item \texttt{Event}: une description de la catastrophe.
\item \texttt{Type}: le type de catastrophe.
\item \texttt{Location}: une description du lieu de la catastrophe.
\item \texttt{OriginalCost}: coût original de la catastrophe en millions de \textit{AUD} ou \textit{NZD}.
\item \texttt{NormCost2011}: coût normalisé en millions de dollars de 2011 (inflation, richesse et population).
\item \texttt{NormCost2014}: coût normalisé en millions de dollars de 2014 (inflation, richesse et population).
\end{itemize}
\

Les tables \ref{tab:3.1} et \ref{tab:3.2} contiennent un résumé statistique des données australiennes. Les tables \ref{tab:3.3} et \ref{tab:3.4} contiennent le même type de résumé pour la Nouvelle-Zélande.

<<echo=FALSE, results=hide>>=
libs <- c('dplyr', 'ggplot2', 'gridExtra', 'ismev', 'evir', 'xtable',
          'summarytools', 'utils', 'QRM', 'CASdatasets', 'tidyr')
sapply(libs, require, character.only = T)

data("auscathist")
data("nzcathist")
@

<<echo=FALSE, results=tex>>=
print(
  xtable(descr(auscathist, stats = "common", transpose = T), caption = "Résumé statistique des variables numériques pour l'Australie", label="tab:3.1", align=rep("c",8), digits=0, table.placement="h")
)

print(
xtable(freq(auscathist$Type), caption = "Distribution du Type de catastrophe pour l'Australie", label="tab:3.2", align=rep("c",6), digits=0, table.placement="h")
)
@

<<echo=FALSE, results=tex>>=
print(
  xtable(descr(nzcathist, stats = "common", transpose = T), caption = "Résumé statistique des variables numériques pour la Nouvelle-Zélande", label="tab:3.3", align=rep("c",8), digits=3, table.placement="h")
)

print(
xtable(freq(nzcathist$Type), caption = "Distribution du Type de catastrophe pour la Nouvelle-Zélande", label="tab:3.4", align=rep("c",6), digits=0, table.placement="h")
)
@


Pour chaque jeu de données, une nouvelle variable du montant de catastrophe est créée à partir de la variable \texttt{NormCost2014} (\texttt{CostUS2019}). Cette nouvelle variable représente le coût ajusté au niveau du 30 juin 2019 en considérant l'indice du prix à la consommation de chaque pays et le coût est également converti en dollar américain. La table \ref{tab:3.5} contient les chiffres utilisés \footnote{https://www.rateinflation.com/consumer-price-index  \newline https://www.exchange-rates.org/Rate/AUD/USD/6-30-2019}.

<<echo=FALSE, results=tex>>=
tab <- data.frame(c(105.9, 974.7), c(114.8, 1039.0), c(0.7031, 0.6722))
rownames(tab) <- c("AUS", "NZ")
colnames(tab) <- c("IPC 2014", "IPC 2019", "Taux de change 2019")

print(
  xtable(tab, caption="Valeurs utilisées pour CostUS2019", label="tab:3.5", align=rep("c",4), digits=4, table.placement="h")
)
@
\

Étant donné que les deux jeux de données sont très semblables, ceux-ci sont regroupés en un seul jeu de données et une variable \texttt{Country} est rajoutée. Étant donné le nombre limité de données disponibles et pour rendre l'analyse pertinente et possible, seulement les variables \texttt{CostUS2019}, \texttt{Year}, \texttt{Country} et \texttt{Type} sont conservées. Les figures \ref{fig:3.1}, \ref{fig:3.2}, \ref{fig:3.3} ainsi que la table \ref{tab:3.6} résument bien le jeu de données final utilisé pour commencer l'analyse.


\begin{figure}[h]
\begin{center}
<<echo=FALSE, fig=TRUE, height=3, width=6>>=
auscathist <- auscathist %>%
    select(Year, Quarter, FirstDay, Event, Type, Location, NormCost2014) %>%
    mutate(Country = as.factor("AUS"))

nzcathist <- nzcathist %>%
    select(Year, Quarter, FirstDay, Event, Type, Location, NormCost2014) %>%
    mutate(Country = as.factor("N-Z"))

auscathist <- auscathist %>%
    mutate(CostUS2019 = NormCost2014 * (114.8/105.9) * .7032) %>%
    select(-NormCost2014)

nzcathist <- nzcathist %>%
    mutate(CostUS2019 = NormCost2014 * (1039.0/974.7) * .6727) %>%
    select(-NormCost2014)

pacicathist <- rbind(auscathist, nzcathist) %>%
    dplyr::filter(CostUS2019 > 0) %>%
    mutate(Type = as.factor(Type)) %>%
    select(Year, Type, Country, CostUS2019)

colnames(pacicathist) <- c("Année", "Type", "Pays", "Montant")

pacicathist <- pacicathist %>% 
    dplyr::filter(Montant < 4000) %>% 
    dplyr::filter(Type != "Earthquake" | Montant < 2000)


grid.arrange(
  pacicathist %>%
    ggplot(aes(log(Montant))) +
    geom_density(alpha=.44, fill=1) +
    theme_minimal() +
    labs(x="log(Montant) (M USD)", y="Densité"),

  pacicathist %>% 
    ggplot(aes(log(Montant), fill=Pays)) + 
    geom_density(alpha=.44) + 
    theme_minimal() +
    labs(x="log(Montant) (M USD)", y="Densité") + 
    theme(legend.position = c(.9,.9)),
  
  ncol=2
)
@
\end{center}
\caption{Densité du logarithme du montant des catastrophes}
\label{fig:3.1}
\end{figure}

\begin{figure}[h]
\begin{center}
<<echo=FALSE, fig=TRUE, height=3, width=6>>=

levels(pacicathist$Pays)[levels(pacicathist$Pays)=="AUS"] <- "Australie"
levels(pacicathist$Pays)[levels(pacicathist$Pays)=="N-Z"] <- "Nouvelle-Zélande"

pacicathist %>% 
    group_by(Pays) %>%
    arrange(Année) %>% 
    mutate(cun = cumsum(as.numeric(Montant>0))) %>% 
    ungroup() %>% 
    ggplot(aes(x=Année, y=cun, col=Pays)) + 
    geom_line() +
    theme_minimal() +
    labs(y="N") + 
    theme(legend.position = c(.25,.8))
@
\end{center}
\caption{Nombre cumulatif de catastrophes par pays}
\label{fig:3.2}
\end{figure}


\begin{figure}[h]
\begin{center}
<<echo=FALSE, fig=TRUE, height=3, width=6>>=
pacicathist %>% 
    ggplot() +
    geom_point(aes(x=Année, y=Montant, col=Pays, alpha=.44)) + 
    facet_wrap(~Pays, scales="free") + 
    theme_bw() +
    theme(legend.position = "")+
    labs(y="Montant (M USD)")
@
\end{center}
\caption{Évolution des catastrophes par pays}
\label{fig:3.3}
\end{figure}   

<<echo=FALSE, results=tex>>=
print(
  xtable(data.frame(pacicathist %>% 
    group_by(Type) %>% 
    summarise(N = n(),
              Moyenne = mean(Montant),
              Écart = sd(Montant), 
              Minimum = min(Montant),
              Médiane = median(Montant),
              Q3 = quantile(Montant, .75),
              Maximum = max(Montant))), 
    caption = "Résumé statistique des montants (M USD) de catastrophes par Type", label="tab:3.6", align=rep("c",9), digits=0, table.placement="t"), include.rownames = FALSE)
@

\clearpage
\section{Approche classique}

Avant d'essayer la nouvelle méthode proposée, les méthodes classiques présentées à au chapitre \ref{chap:notions} sont appliquées pour être en mesure d'évaluer la valeur de la nouvelle méthode. Plus spécifiquement, l'approche \textit{POT} présentée à la section \ref{sec:pot} est appliquée dans la présente section étant donné que c'est ce type de modèle qui est appliqué dans les prochaines sections. À noter que les différents calculs de cette section nécessitant des techniques numériques sont faits avec le paquetage \texttt{ismev}. L'approche ici est donc de prendre l'ensemble des données, de choisir un seuil $u$ approprié et d'estimer les paramètres de la loi Pareto généralisée avec les excès de seuil, le tout en tenant compte d'aucunes variables exogènes. Comme mentionné, la première étape de cette méthodologie est le choix de la valeur du seuil $u$. La première méthode demande de tracer le \textit{mean residual plot} dont les points mentionnés dans l'équation \ref{eq:1.2.5}. Après un certaine valeur $u$ pour lequel la distribution est appropriée, le graphique devrait être linéaire en $u$. La figure \ref{fig:3.4} montre que déjà à partir de petites valeurs, cette conditon est respectée, il est ensuite difficile, voire subjectif de choisir une valeur précise. Ici, le graphique suggère de sélectionner une valeur entre 0 et 10.
\begin{figure}[h]
\begin{center}
<<echo=FALSE, fig=TRUE, height=4, width=7>>=
par(mfrow=c(1,2))
mrl.plot(pacicathist$Montant)
mrl.plot(pacicathist$Montant, umax = 25)
@
\end{center}
\caption{\textit{Mean residual plot}}
\label{fig:3.4}
\end{figure}

La deuxième méthode mentionnée à la section \ref{sec:pot} propose d'estimer les paramètres du modèle pour différentes valeurs de $u$. Comme expliqué dans cette section, $\sigma^*$ et $\xi$ devraient rester constants au-delà de $u_0$. La figure \ref{fig:3.5} montre des résulats plus concluants que la figure \ref{fig:3.4}. En effet, les valeurs de $\sigma^*$ et de $\xi$ deviennent constantes environ à $u=10$. L'analyse des deux différentes techniques de sélection de seuil mènent donc à une sélection de $u=10$. Environ 64\% des données dépassent ce seuil, un bon nombre de données est donc utile pour la modélisation des excès.
\begin{figure}[h]
\begin{center}
<<echo=FALSE, fig=TRUE, height=5, width=6>>=
par(mfrow=c(1,1))
gpd.fitrange(pacicathist$Montant, 
             nint=20,
             umin=1, 
             umax = 50)
@
\end{center}
\caption{Estimation des paramètres du modèle pour différents seuils}
\label{fig:3.5}
\end{figure}

Après avoir sélectionné le seuil, il faut ensuite estimer les paramètres de la loi Pareto généralisée avec la méthode du maximum de vraisemblance. Les différents détails de ce calcul se trouvent dans les équations \ref{eq:1.2.6} et \ref{eq:1.2.7}. Voici les résultats obtenus avec un intervalle de confiance de 95 \%.

\begin{equation*}
\begin{gathered}
(\hat\sigma,\hat\xi) = (49.329951;\ 0.941132)\\
\ell(\hat\sigma,\hat\xi) = -1308.013\\
\text{Var}(\hat\sigma) = 41.9446912\\
\text{Var}(\hat\xi) = 0.01673518
\end{gathered}
\end{equation*}
\

\begin{equation*}
\begin{gathered}
\hat\zeta_u = 0.6418338\\
\text{Var}(\hat\zeta_u) = 0.000658691
\end{gathered}
\end{equation*}
\

\begin{equation*}
\begin{gathered}
IC_{\hat\sigma} = (36.6362993;\ 62.023603)\\
IC_{\hat\xi} = (0.6875822;\ 1.194682)\\
IC_{\hat\zeta_u} = (0.5915314;\ 0.6921362)
\end{gathered}
\end{equation*}
\

Suite aux résultats obtenus, les graphiques de validation mentionnés à la section \ref{sec:pot} peuvent être tracés pour juger de la qualité du modèle. La figure \ref{fig:3.6} montre des résultats qui ne sont pas désastreux, mais qui sont loin d'être concluants en ce qui concerne l'ajustement des données au modèle proposé dans la présente section. Le graphique \textit{P-P} est tout de même adéquat, mais les trois autres graphiques sont loins de l'être. Les graphiques \textit{Q-Q} et celui de la densité obtenue montrent que le modèle représentent mal les données utilisées et le graphique des niveaux de retour montre que dès que la période de retour est un peu élevé, le niveau obtenu est extrêmement volatile. 
\


Pour conclure, le modèle proposé dans cette section représente un modèle de base qui considère toutes les données de la manière sans égard aux informations supplémentaires disponibles par rapport aux montants des catastrophes. Il n'est donc pas surprenant de voir que cette approche n'est pas tout à fait adéquate dans le cas présent, mais reste que cette approche est viable, rapide et peut être une bonne solution lorsque seulement les montants sont disponibles. Il est également important de savoir que le modèle testé dans cette section est la base de tous autres modèles plus avancés, tous comme les modèles qui seront testés aux prochaines sections.
\begin{figure}[h]
\begin{center}
<<echo=FALSE, results=tex, fig=TRUE, height=5.5, width=7>>=
gpd.diag(gpd.fit(pacicathist$Montant, 10, show=FALSE))
@
\end{center}
\caption{Graphiques de validation du modèle}
\label{fig:3.6}
\end{figure}


\clearpage
\section{Approche dynamique à deux variables}
\label{sec:3.3}

Cette section applique la méthodologie et le modèle proposés au chapitre \ref{chap:article} avec deux variables, l'année et le pays. On considère donc une variable numérique de temps ainsi qu'une variable catégorique à deux niveaux. Seulement deux variables sont initialemment utilisées étant donné que c'est ce que l'article étudié utilise pour ilustrer la méthode. De plus, étant donné le nombre limité de données disponibles, il est préférable de ne pas commencer avec un nombre de sous-groupes trop élevés. Une troisième variable sera considérée à la section \ref{sec:3.4}. Avant même de commencer, les figures \ref{fig:3.1} et \ref{fig:3.2} suggèrent que les paramètres du modèles devraient bel et bien varier entre les deux pays et à travers le temps. Dans le cadre de la modélisation, seulement l'ajustement du paramètre $\rho$ est inclu dans le rapport, voir \ref{eq:2.2.13}. Un seuil de valeur 10 M USD est toujours utilisé, voir les figures \ref{fig:3.4} et \ref{fig:3.5}. 
\\

Premièrement, le paramètre $\rho$ du modèle est ajusté aux données. Après avoir statistiquement comparé les différents modèles, le modèle sélectionné pour $\hat\rho$ dépend du pays et du temps et a la forme suivante:
\begin{equation}\label{eq:3.3.1}
\log\Bigg(\frac{\hat\rho(x,t)}{1-\hat\rho(x,t)}\Bigg) = \hat{f}_\rho(pays) + \hat{h}^{(2)}_\rho(annee)
\end{equation}
où ${h}^{(\text{Df})}$ représente une spline naturelle quadratique avec $\text{Df}$ degrés de liberté.
\\

<<echo=FALSE, results=hide>>=
paci.1 <- pacicathist %>% 
    select(-Type)

rate.exc.1 <- as.data.frame(paci.1 %>% 
                                mutate(rate.exc = as.numeric(Montant > 10)))


modrho <- gam(rate.exc ~ Pays + s(Année, fx=TRUE, k=2+1, bs="cr", by=Pays) - 1, 
              data=rate.exc.1, family=binomial(link=logit)) 


rhoFit <- QRM:::get.gam.fit(modrho)   

rhoPred <- QRM:::gam.predict(modrho, alpha=.05, value="rho")


rhoPred$predict <- exp(rhoPred$predict) / (exp(rhoPred$predict) + 1)
rhoPred$CI.low <- exp(rhoPred$CI.low) / (exp(rhoPred$CI.low) + 1)
rhoPred$CI.up <- exp(rhoPred$CI.up) / (exp(rhoPred$CI.up) + 1)



results.rho <- data.frame(rhoPred$covar, Pred=rhoPred$predict,
                          CI.low=rhoPred$CI.low, CI.up=rhoPred$CI.up)
@

Voici une représentation graphique des résultats obtenus.
\begin{figure}[h]
\begin{center}
<<echo=FALSE, results=tex, fig=TRUE, height=3, width=6>>=
results.rho %>% 
    ggplot() + 
    geom_errorbar(aes(x=Année, ymin=CI.low, ymax=CI.up), alpha=.44, width=.1) +
    geom_point(aes(x=Année, y=Pred, col=Pays)) + 
    facet_wrap(~Pays) + 
    theme_bw() + 
    theme(legend.position = "", strip.text = element_text(size=12)) + 
    labs(y=expression(hat(rho)))
@
\end{center}
\caption{Prédictions du taux d'excès de seuil avec intervalles de confiance à 95\%}
\label{fig:3.7}
\end{figure}

La figure \ref{fig:3.7} indique qu'il y a bel et bien une différence entre les pays et à travers le temps. Plus spécifiquement, les catastrophes australiennes dépassent beaucoup plus souvent le seuil de 10 millions et la figure indique également un paramètre élevé et constant pendant quelques années pour ensuite observé une diminution de celui-ci pour que finalement celui-ci remonte à un certain niveau.
\\

Ensuite, les paramètres de la loi Pareto généralisée sont ajustés aux données. Après avoir statistiquement comparé les différents modèles, le modèle sélectionné pour $\hat\xi$ dépend du pays et non du temps et a la forme suivante:
\begin{equation}\label{eq:3.3.2}
\hat\xi(x,t) = \hat{f}_\xi(pays)
\end{equation}

De son côté, le modèle sélectionné pour $\hat\beta$ dépend du pays et du temps et a la forme suivante:
\begin{equation}\label{eq:3.3.3}
\hat\beta(x,t) = \hat{f}_\beta(pays) + \hat{h}^{(3)}_\beta(annee)
\end{equation}

<<echo=FALSE, results=hide>>=
bootGPD <- QRM::gamGPDboot(paci.1, B=500, threshold=10, datvar="Montant",
                         
                         xiFrhs = ~ Pays - 1, 
                         nuFrhs = ~ Pays + s(Année, fx=TRUE, k=3+1, bs="cr", by=Pays) - 1, 
                         
                         niter=500, eps.xi=.005, eps.nu=.005)



xibetaFit <- QRM::get.GPD.fit(bootGPD, alpha=.05) 

xibetaPred <- QRM::GPD.predict(bootGPD)


results.xi <- data.frame(xibetaFit$xi$covar, Pred=xibetaFit$xi$fit,
                          CI.low=xibetaFit$xi$CI.low, CI.up=xibetaFit$xi$CI.up)


results.beta <- data.frame(xibetaFit$beta$covar, Pred=xibetaFit$beta$fit,
                         CI.low=xibetaFit$beta$CI.low, CI.up=xibetaFit$beta$CI.up)

@


Les figures \ref{fig:3.8} et \ref{fig:3.9} présentent une représentation graphique des résultats obtenus pour les deux paramètres.
\begin{figure}[h]
\begin{center}
<<echo=FALSE, results=tex, fig=TRUE, height=3, width=6>>=
results.xi %>% 
    ggplot() + 
    geom_errorbar(aes(x=Pays, ymin=CI.low, ymax=CI.up), alpha=.44, width=.1) +
    geom_point(aes(x=Pays, y=Pred, size=2, col=Pays)) + 
    theme_minimal() + 
    theme(legend.position = "", strip.text = element_text(size=12))+ 
    labs(y=expression(hat(xi))) +
    ylim(c(0,1))
@
\end{center}
\caption{Prédictions du paramètre $\xi$ avec intervalles de confiance à 95\%}
\label{fig:3.8}
\end{figure}

La figure \ref{fig:3.8} montre qu'il y a bel et bien une différence entre les deux pays et que cette différence est très importante. Le fait que le paramètre de l'Australie soit plus élevé fait du sens, car la distribution des catastrophes australiennes a une queue plus épaisse que celle des catastrophes de la Nouvelle-Zélande. 
\\

\begin{figure}[h]
\begin{center}
<<echo=FALSE, results=tex, fig=TRUE, height=3, width=6>>=
results.beta %>% 
    ggplot() + 
    geom_point(aes(x=Année, y=Pred, col=Pays), size=2) + 
    geom_line(aes(x=Année, y=Pred)) + 
    geom_line(aes(x=Année, y=CI.low), linetype="dashed", alpha=.8) + 
    geom_line(aes(x=Année, y=CI.up), linetype="dashed", alpha=.8) + 
    facet_wrap(~Pays, scales="free") + 
    theme_bw() + 
    theme(legend.position = "", strip.text = element_text(size=12))+ 
    labs(y=expression(hat(beta)))
@
\end{center}
\caption{Prédictions du paramètre $\beta$ avec intervalles de confiance à 95\%}
\label{fig:3.9}
\end{figure}

La figure \ref{fig:3.9} montre bien que les deux variables sélectionnées ont bel et bien un impact sur le paramètre $\beta$. Tout comme avec $\xi$, il est logique que les paramètres de la Nouvelle-Zélande soient inférieurs que ceux de l'Australie tout simplement parce que les pertes sont généralement plus élevées, voir la figure \ref{fig:3.1}. La figure montre également que, de façon générale, le paramètre dimiunue avec le temps.
\\

Même si les paramètres du modèle sont maintenant obtenus, il est important de vérifier l'adéquation du modèle avant d'effectuer n'importe quelle inférence. Comme l'explique l'équation \ref{eq:2.2.12}, une validation possible est de vérifier si les $r_i$ se comportent comme des variables aléatoires indépendantes suivant une loi exponentielle standards. Le graphique \textit{Q-Q} de cette loi est donc tracé à la figure \ref{fig:3.10}.
<<echo=FALSE, results=hide>>=
covar <- xibetaFit$beta$covar 


count.cov <- as.data.frame(covar %>% count(Pays))

vec.cov <- c()
for (i in nrow(count.cov):1){
    vec.cov <- c(rep(i, count.cov$n[i]), vec.cov)
}


xibetaFit$xi$fit <- xibetaFit$xi$fit[vec.cov]
xibetaFit$xi$CI.low <- xibetaFit$xi$CI.low[vec.cov]
xibetaFit$xi$CI.up <- xibetaFit$xi$CI.up[vec.cov]

xibetaFit$xi$covar <- covar



xibetaFit.xi.boot2 <- matrix(ncol = 500)
for (i in nrow(count.cov):1){
    xibetaFit.xi.boot2 <- rbind(
        do.call(rbind, replicate(count.cov$n[i], xibetaFit$xi$boot[i,], simplify=FALSE)),
        xibetaFit.xi.boot2
    )
}

xibetaFit$xi$boot <- xibetaFit.xi.boot2[-length(xibetaFit.xi.boot2[, 1]),]



xiFit.mat <- cbind(xibetaFit$xi$fit, xibetaFit$xi$boot)

betaFit.mat <- cbind(xibetaFit$beta$fit, xibetaFit$beta$boot)


rho.res <- data.frame(rhoFit$covar, rhoFit$fit)

rho.res.sel <- covar %>% 
    inner_join(rho.res)



final.results <- data.frame(Covar=xibetaFit$beta$covar,
                            rho = rho.res.sel$rhoFit.fit,
                            xi = xibetaFit$xi$fit,
                            xi.low = xibetaFit$xi$CI.low,
                            xi.up = xibetaFit$xi$CI.up,
                            beta = xibetaFit$beta$fit,
                            beta.low = xibetaFit$beta$CI.low,
                            beta.up = xibetaFit$beta$CI.up)





VaR <- cbind(covar, fit=sapply(1:(500+1), function(j)
    risk.measure(cbind(rho.res.sel$rhoFit.fit, xiFit.mat[,j], betaFit.mat[,j]),
                 alpha=.99, u=10, method="VaR")
))

VaR.boot <- VaR %>% select(-Pays, -Année, -fit.1)

VaR.fit <- data.frame(covar, 
                      fit    = VaR[, "fit.1"], 
                      CI.low = apply(VaR.boot, 1, quantile, probs=.05/2),
                      CI.up  = apply(VaR.boot, 1, quantile, probs=1-.05/2))



final.results <- final.results %>% 
    rename(Pays = Covar.Pays,
           Année = Covar.Année) 


paci.1.param <- paci.1 %>% 
    inner_join(final.results) %>% 
    
    dplyr::filter(Montant > 10) %>% 
    mutate(Y = Montant - 10)



paci.1.param$ri <- sapply(1:nrow(paci.1.param), 
                          function(i) -log(1 - pGPD(paci.1.param$Y[i], 
                                                    paci.1.param$xi[i], 
                                                    paci.1.param$beta[i])))

@

La figure montre que la calibration du modèle n'est pas tout si mal et même bonne dans l'ensemble. Le graphique n'est pas catastrophique et tout de même mieux que celui de la figure \ref{fig:3.6}. Peut-être que l'ajout d'une troisième variable à la section \ref{sec:3.4} va améliorer la qualité du modèle obtenu.
\\

Ensuite, à l'aide de l'équation \ref{eq:2.2.13}, les différentes $\widehat{\text{VaR}_{0.99}}$ peuvent être calculées. La figure \ref{fig:3.11} montre les résultats. 
\begin{figure}[h]
\begin{center}
<<echo=FALSE, results=tex, fig=TRUE, height=4, width=6>>=
require(qqplotr)
paci.1.param %>% 
    ggplot(aes(sample = ri)) +
    stat_qq_band(distribution = "exp", dparams = 1, conf = .95, alpha=.2, fill="blue") +
    stat_qq_point(distribution = "exp", dparams = 1) + 
    stat_qq_line(distribution = "exp", dparams = 1,) + 
    theme_minimal() +
    labs(x="Valeurs théoriques", y="Quantiles des résidus du modèle")
  
@
\end{center}
\caption{Graphique \textit{Q-Q} de $\text{Exp}(1)$}
\label{fig:3.10}
\end{figure}

\begin{figure}[h]
\begin{center}
<<echo=FALSE, results=tex, fig=TRUE, height=3, width=6>>=
VaR.fit %>%  
    ggplot() + 
    geom_point(aes(x=Année, y=fit, col=Pays), size=2) + 
    geom_line(aes(x=Année, y=fit)) + 
    geom_line(aes(x=Année, y=CI.low), linetype="dashed", alpha=.8) + 
    geom_line(aes(x=Année, y=CI.up), linetype="dashed", alpha=.8) + 
    facet_wrap(~Pays, scales = "free") + 
    theme_bw() + 
    theme(legend.position = "", strip.text = element_text(size=12)) +
    labs(y=expression(hat(VaR)))
@
\end{center}
\caption{$\widehat{\text{VaR}_{0.99}}$ avec intervalles de confiance à 95\%}
\label{fig:3.11}
\end{figure}

Il est logique de voir que la mesure de risque dépend du temps et du pays car celle-ci est obtenue avec les paramètres estimés. Tout comme avec les paramètres, il est logique que les valeurs obtenues pour la Nouvelle-Zélande soient inférieurs que celles de l'Australie tout simplement parce que les pertes sont généralement plus élevées pour l'Australie.
\\

C'est ce qui conclut cette section. La méthodologie proposée par les auteurs fonctionne et donnent les résultats escomptés lorque le temps ainsi qu'une variable catégorique sont considérés. Le modèle final obtenu n'est pas parfait, mais est tout de même une amélioration du modèle classique vu à la section \ref{sec:pot}.


\clearpage
\section{Approche dynamique à trois variables}
\label{sec:3.4}

Dans cette section, la même procédure que la section \ref{sec:3.3} est employée, mais la variable représentant le type de catastrophes est maintenant disponible. Un seuil de 10 M USD est toujours utilisé. Il y a 11 types différents dans les données. Une démarche complète de modélisation a été faite avec tous les types non regroupés, mais étant donné le nombre limité de données, les résultats ne furent pas concluants et les détails de ce modèle ne sont pas incluts dans ce rapport. Pour être en mesure de travailler avec cette troisième variable, un regroupement des types a dû être fait. La table \ref{tab:3.7} présente un résumé de ce regroupement. Sans même commencer la modélisation, la table \ref{tab:3.6} montre que le type de catastrophes va probablement s'avérer significatif pour les différents paramètres du modèle étant donnée que la distribution du montant de catastrophe varie beaucoup entre les différents types. 

<<echo=FALSE, results=hide>>=
paci.3 <- pacicathist

Type2 <- data.frame(Type = c("Bushfire", "Hailstorm", "Cyclone", 
                             "Flood", "Flood, Storm", "Storm", 
                             "Other", "Tornado", "Earthquake", "Weather", "Power outage"),
                    Type2 = c("Bushfire", "Hailstorm", "Cyclone",
                              rep("Flood, Storm",3), 
                              rep("Other",5)))

paci.3 <- paci.3 %>% 
    inner_join(Type2)

paci.3 %>% 
    count(Type2) %>% 
    arrange(-n)


paci.3 <- paci.3 %>% 
    mutate(Type=as.factor(Type2)) %>% 
    select(-Type2)


paci.3 <- droplevels(paci.3)
@

<<echo=FALSE, results=tex>>=
print(
  xtable(Type2, caption = "Regroupement des types de catastrophes", label="tab:3.7", align=rep("c",3), digits=0, table.placement="h"), include.rownames = FALSE
)
@

Tout comme lors de section précédente, le paramètre $\rho$ du modèle est le premier à être ajusté aux données. Après avoir statistiquement comparé les différents modèles, le modèle sélectionné pour $\hat\rho$ dépend du pays, du type et du temps et a la forme suivante:
\begin{equation}\label{eq:3.4.1}
\log\Bigg(\frac{\hat\rho(x,t)}{1-\hat\rho(x,t)}\Bigg) = \hat{f}_\rho(pays) + \hat{f}_\rho(type) + \hat{h}^{(2)}_\rho(annee)
\end{equation}

La figure \ref{fig:3.12} montre les résultats pour l'Australie et la figure ref{fig:3.13} montre ceux pour la Nouvelle-Zélande.
\\

<<echo=FALSE, results=hide>>=
rate.exc.3 <- as.data.frame(paci.3 %>% 
                                mutate(rate.exc = as.numeric(Montant > 10)))

modrho <- gam(rate.exc ~ Pays + s(Année, fx=TRUE, k=2+1, bs="cr", by=Pays) + Type - 1, 
              data=rate.exc.3, family=binomial(link=logit))


rhoFit <- QRM:::get.gam.fit(modrho)   

rhoPred <- QRM:::gam.predict(modrho, alpha=.05, value="rho")


rhoPred$predict <- exp(rhoPred$predict) / (exp(rhoPred$predict) + 1)
rhoPred$CI.low <- exp(rhoPred$CI.low) / (exp(rhoPred$CI.low) + 1)
rhoPred$CI.up <- exp(rhoPred$CI.up) / (exp(rhoPred$CI.up) + 1)



results.rho <- data.frame(rhoPred$covar, Pred=rhoPred$predict,
                          CI.low=rhoPred$CI.low, CI.up=rhoPred$CI.up)

@


\begin{figure}[h]
\begin{center}
<<echo=FALSE, results=tex, fig=TRUE, height=3, width=6>>=
results.rho %>% 
    dplyr::filter(Pays == "Australie") %>% 
    ggplot() + 
    geom_errorbar(aes(x=Année, ymin=CI.low, ymax=CI.up), alpha=.44, width=.1) +
    geom_point(aes(x=Année, y=Pred, col=Type)) + 
    facet_wrap(~Type) + 
    theme_bw() + 
    theme(legend.position = "", strip.text = element_text(size=12)) + 
    labs(y=expression(hat(rho)))
@
\end{center}
\caption{Prédictions du paramètre $\rho$ pour l'Australie avec intervalles de confiance à 95\%}
\label{fig:3.12}
\end{figure}

\begin{figure}[h]
\begin{center}
<<echo=FALSE, results=tex, fig=TRUE, height=3, width=6>>=
results.rho %>% 
    dplyr::filter(Pays == "Nouvelle-Zélande") %>% 
    ggplot() + 
    geom_errorbar(aes(x=Année, ymin=CI.low, ymax=CI.up), alpha=.44, width=.1) +
    geom_point(aes(x=Année, y=Pred, col=Type)) + 
    facet_wrap(~Type) + 
    theme_bw() + 
    theme(legend.position = "", strip.text = element_text(size=12)) + 
    labs(y=expression(hat(rho)))
@
\end{center}
\caption{Prédictions du paramètre $\rho$ pour la Nouvelle-Zélande avec intervalles de confiance à 95\%}
\label{fig:3.13}
\end{figure}

Les deux figures montrent que, comme dans la section précédente, il est clair que le paramètre est différent entre les deux pays et que celui-ci dépend du temps. De plus, même si cela est moins significatif que les pour les autres variables, les figures montrent également que le type de catastrophes est important pour la détermination du paramètre. Les courbes sont semblables par pays, mais le type amène une certaine translation verticale de la courbe. Cependant, on peut voir que les intervalles de confiance sont plus larges que ceux de la figure \ref{fig:3.7} étant donné qu'il y a maintenant moins de données par sous-groupes de variables.
\\

Suivant à nouveau la même démarche que la section précédente, les paramètres de la loi Pareto généralisée sont ajustés aux données. Après avoir statistiquement comparé les différents modèles, le modèle sélectionné pour $\hat\xi$ dépend du pays, du type et non du temps et a la forme suivante:
\begin{equation}\label{eq:3.4.2}
\hat\xi(x,t) = \hat{f}_\xi(pays) + \hat{f}_\xi(type)
\end{equation}

De son côté, le modèle sélectionné pour $\hat\beta$ dépend du pays, du type et du temps et a la forme suivante:
\begin{equation}\label{eq:3.4.3}
\hat\beta(x,t) = \hat{f}_\beta(pays) + \hat{f}_\xi(type) + \hat{h}^{(4)}_\beta(annee)
\end{equation}

<<echo=FALSE, results=hide>>=
bootGPD <- QRM::gamGPDboot(paci.3, B=500, threshold=10, datvar="Montant",
                            
                            xiFrhs = ~ Pays + Type - 1,  
                            nuFrhs = ~ Pays + Type + s(Année, fx=TRUE, k=4+1, bs="cr", by=Pays) - 1, 
                            
                            niter=500, eps.xi=.005, eps.nu=.005)





xibetaFit <- QRM::get.GPD.fit(bootGPD, alpha=.05) 

xibetaPred <- QRM::GPD.predict(bootGPD)



results.xi <- data.frame(xibetaFit$xi$covar, Pred=xibetaFit$xi$fit,
                         CI.low=xibetaFit$xi$CI.low, CI.up=xibetaFit$xi$CI.up)


results.beta <- data.frame(xibetaFit$beta$covar, Pred=xibetaFit$beta$fit,
                           CI.low=xibetaFit$beta$CI.low, CI.up=xibetaFit$beta$CI.up)

@

Les figures \ref{fig:3.14}, \ref{fig:3.15} et \ref{fig:3.16} présentent une représentation graphique des résultats obtenus pour les deux paramètres.
\begin{figure}[h]
\begin{center}
<<echo=FALSE, results=tex, fig=TRUE, height=3, width=6>>=
results.xi %>% 
    ggplot() + 
    geom_errorbar(aes(x=Type, ymin=CI.low, ymax=CI.up), alpha=.44, width=.1) +
    geom_point(aes(x=Type, y=Pred, col=Type), size=2.5) + 
    coord_flip() + 
    facet_wrap(~Pays) + 
    theme_bw() + 
    theme(legend.position = "", strip.text = element_text(size=12)) + 
    labs(y=expression(hat(xi)))

@
\end{center}
\caption{Prédictions du paramètre $\xi$ avec intervalles de confiance à 95\%}
\label{fig:3.14}
\end{figure}

La figure \ref{fig:3.14} montre qu'il y a bel et bien une différence entre les différents types et que celle-ci est consirédablement importante. Ici, le comportement entre les types est semblable pour les deux pays, mais la figure montre clairement que les paramètres de l'Australie sont supérieurs à ceux de la Nouvelle-Zélande, ce qui est logique. De plus, contrairement aux résultats obtenus à la figure \ref{fig:3.8} où les résultats étaient non problématiques, les résultats obtenus ici contiennent deux valeurs (pour le même type) supérieures à 1, ce qui représente un modèle à moyenne infinie. Deux intervalles de confiance vont également jusqu'à des valeurs négatives sans toutefois atteindre -1, ce qui est très problématique.
\\

\begin{figure}[h]
\begin{center}
<<echo=FALSE, results=tex, fig=TRUE, height=3, width=6>>=
results.beta %>% 
    dplyr::filter(Pays=="Australie") %>% 
    ggplot() + 
    geom_point(aes(x=Année, y=Pred, col=Type), size=2) + 
    geom_line(aes(x=Année, y=Pred)) + 
    geom_line(aes(x=Année, y=CI.low), linetype="dashed", alpha=.8) + 
    geom_line(aes(x=Année, y=CI.up), linetype="dashed", alpha=.8) + 
    facet_wrap(~Type, scales = "free") + 
    theme_bw() + 
    theme(legend.position = "", strip.text = element_text(size=12)) + 
    labs(y=expression(hat(beta)))
@
\end{center}
\caption{Prédictions du paramètre $\beta$ pour l'Australie avec intervalles de confiance à 95\%}
\label{fig:3.15}
\end{figure}


\begin{figure}[h]
\begin{center}
<<echo=FALSE, results=tex, fig=TRUE, height=3, width=6>>=
results.beta %>% 
    dplyr::filter(Pays=="Nouvelle-Zélande") %>% 
    ggplot() + 
    geom_point(aes(x=Année, y=Pred, col=Type), size=2) + 
    geom_line(aes(x=Année, y=Pred)) + 
    geom_line(aes(x=Année, y=CI.low), linetype="dashed", alpha=.8) + 
    geom_line(aes(x=Année, y=CI.up), linetype="dashed", alpha=.8) + 
    facet_wrap(~Type, ) + 
    theme_bw() + 
    theme(legend.position = "", strip.text = element_text(size=12)) + 
    labs(y=expression(hat(beta)))
@
\end{center}
\caption{Prédictions du paramètre $\beta$ pour la Nouvelle-Zélande avec intervalles de confiance à 95\%}
\label{fig:3.16}
\end{figure}

Les figures \ref{fig:3.15} et \ref{fig:3.16} montrent bien qu'encore une fois, le pays a une importance très significative pour la détermination des paramètres. De plus, même si cela est moins considérable que pour $\xi$, les figures montrent qu'il y a bel et bien une différence entre les différents types. Pour l'Australie, les courbes sont semblables, mais tout comme avec $\rho$, le type amène une certaine translation verticale de la courbe. Pour la Nouvelle-Zélande, le type amène également des courbes différentes. Un problème flagrant est remarquable à la figure \ref{fig:3.16} pour laquelle il y a très peu de points et donc des résultats peu crédibles. Ce problème est dû au fait qu'il y a déjà très peu de données et qu'en plus une troisième variable est rajoutée, ce qui rend les sous-groupes de covariables moins populés. Une autre cause vient du fait que seulement les données au-dessus du seuil $u$ sont utilisées pour la modélisation et la Nouvelle-Zélande présente beaucoup moins de pertes qui remplissent ce critère.
\\

Il est maintenant important de vérifier l'adéquation du modèle avant d'effectuer n'importe quelle inférence. Cette étape est également utile pour voir si l'ajout d'une troisième variable améliore le modèle. Le même type de graphique que la figure \ref{fig:3.10} est tracé à la figure \ref{fig:3.17}. 


<<echo=FALSE, results=hide>>=
covar <- xibetaFit$beta$covar 


count.cov <- as.data.frame(covar %>% count(Pays, Type))

vec.cov <- c()
for (i in nrow(count.cov):1){
    vec.cov <- c(rep(i, count.cov$n[i]), vec.cov)
}


xibetaFit$xi$fit <- xibetaFit$xi$fit[vec.cov]
xibetaFit$xi$CI.low <- xibetaFit$xi$CI.low[vec.cov]
xibetaFit$xi$CI.up <- xibetaFit$xi$CI.up[vec.cov]

xibetaFit$xi$covar <- covar



xibetaFit.xi.boot2 <- matrix(ncol = 500)
for (i in nrow(count.cov):1){
    xibetaFit.xi.boot2 <- rbind(
        do.call(rbind, replicate(count.cov$n[i], xibetaFit$xi$boot[i,], simplify=FALSE)),
        xibetaFit.xi.boot2
    )
}

xibetaFit$xi$boot <- xibetaFit.xi.boot2[-length(xibetaFit.xi.boot2[, 1]),]



xiFit.mat <- cbind(xibetaFit$xi$fit, xibetaFit$xi$boot)

betaFit.mat <- cbind(xibetaFit$beta$fit, xibetaFit$beta$boot)


rho.res <- data.frame(rhoFit$covar, rhoFit$fit)

rho.res.sel <- covar %>% 
    inner_join(rho.res)



final.results <- data.frame(Covar=xibetaFit$beta$covar,
                            rho = rho.res.sel$rhoFit.fit,
                            xi = xibetaFit$xi$fit,
                            xi.low = xibetaFit$xi$CI.low,
                            xi.up = xibetaFit$xi$CI.up,
                            beta = xibetaFit$beta$fit,
                            beta.low = xibetaFit$beta$CI.low,
                            beta.up = xibetaFit$beta$CI.up)





VaR <- cbind(covar, fit=sapply(1:(500+1), function(j)
    risk.measure(cbind(rho.res.sel$rhoFit.fit, xiFit.mat[,j], betaFit.mat[,j]),
                 alpha=.99, u=10, method="VaR")
))

VaR.boot <- VaR %>% select(-Pays, -Année, -Type, -fit.1)

VaR.fit <- data.frame(covar, 
                      fit    = VaR[, "fit.1"], 
                      CI.low = apply(VaR.boot, 1, quantile, probs=.05/2),
                      CI.up  = apply(VaR.boot, 1, quantile, probs=1-.05/2))



final.results <- final.results %>% 
    rename(Pays = Covar.Pays,
           Type = Covar.Type,
           Année = Covar.Année) 


paci.3.param <- paci.3 %>% 
    inner_join(final.results) %>% 
    
    dplyr::filter(Montant > 10) %>% 
    mutate(Y = Montant - 10)



paci.3.param$ri <- sapply(1:nrow(paci.3.param), 
                    function(i) -log(1 - pGPD(paci.3.param$Y[i], 
                                              paci.3.param$xi[i], 
                                              paci.3.param$beta[i])))

@


\begin{figure}[h]
\begin{center}
<<echo=FALSE, results=tex, fig=TRUE, height=4, width=6>>=
require(qqplotr)
paci.3.param %>% 
    ggplot(aes(sample = ri)) +
    stat_qq_band(distribution = "exp", dparams = 1, conf = .95, alpha=.2, fill="blue") +
    stat_qq_point(distribution = "exp", dparams = 1) + 
    stat_qq_line(distribution = "exp", dparams = 1,) + 
    theme_minimal() +
    labs(x="Valeurs théoriques", y="Quantiles des résidus du modèle")
  
@
\end{center}
\caption{Graphique \textit{Q-Q} de $\text{Exp}(1)$}
\label{fig:3.17}
\end{figure}

Le résultat obtenu à la figure \ref{fig:3.17} est, dans l'ensemble, très concluant, tout comme celui obtenu à la figure \ref{fig:3.10}. Il est difficile de dire lequel des graphiques est meilleur.


Les différentes $\widehat{\text{VaR}_{0.99}}$ peuvent maintenant être calculées. Les figures \ref{fig:3.18} et \ref{fig:3.19} montrent les résultats obtenus pour les deux pays. 
\begin{figure}[h]
\begin{center}
<<echo=FALSE, results=tex, fig=TRUE, height=4, width=6>>=
VaR.fit %>% 
    dplyr::filter(Pays=="Australie") %>% 
    ggplot() + 
    geom_point(aes(x=Année, y=fit, col=Type), size=2) + 
    geom_line(aes(x=Année, y=fit)) + 
    geom_line(aes(x=Année, y=CI.low), linetype="dashed", alpha=.8) + 
    geom_line(aes(x=Année, y=CI.up), linetype="dashed", alpha=.8) + 
    facet_wrap(~Type, scales="free") + 
    theme_bw() + 
    theme(legend.position = "", strip.text = element_text(size=12)) +
    labs(y=expression(hat(VaR)))
  
@
\end{center}
\caption{$\widehat{\text{VaR}_{0.99}}$ avec intervalles de confiance à 95\%}
\label{fig:3.18}
\end{figure}

\begin{figure}[h]
\begin{center}
<<echo=FALSE, results=tex, fig=TRUE, height=3, width=6>>=
VaR.fit %>% 
    dplyr::filter(Pays=="Nouvelle-Zélande") %>% 
    ggplot() + 
    geom_point(aes(x=Année, y=fit, col=Type), size=2) + 
    geom_line(aes(x=Année, y=fit)) + 
    geom_line(aes(x=Année, y=CI.low), linetype="dashed", alpha=.8) + 
    geom_line(aes(x=Année, y=CI.up), linetype="dashed", alpha=.8) + 
    facet_wrap(~Type, scales="free") + 
    theme_bw() + 
    theme(legend.position = "", strip.text = element_text(size=12)) +
    labs(y=expression(hat(VaR)))
@
\end{center}
\caption{$\widehat{\text{VaR}_{0.99}}$ avec intervalles de confiance à 95\%}
\label{fig:3.19}
\end{figure}

Tout comme à la section précédente, il est logique de voir que la mesure de risque dépend du temps, du type et du pays car celle-ci est obtenue avec les paramètres estimés et que les valeurs obtenues pour la Nouvelle-Zélande soient inférieurs que celles de l'Australie tout simplement parce que les pertes sont généralement plus élevées pour l'Australie.
\\

C'est ce qui conclut cette section. Cette section a montré que l'ajout d'une troisième variable catégorique est possible si celle-ci n'a pas trop de niveaux. Le modèle obtenu est adéquat, mais la qualité de celui-ci n'est pas grandement différente avec celle du modèle développé à la section \ref{sec:3.3} en plus que le modèle de la présente section présente des paramètres et des mesures de risques plus volatiles et moins crédibles. 